{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10bb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e19025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4765fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:01<00:00, 7650099.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 28786999.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 4259311.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 4528293.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f15f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60e6938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #def __init__(self):\n",
    "        #super(Net, self).__init__()\n",
    "        #self.fc1 = nn.Linear(28*28, 128)\n",
    "        #self.fc2 = nn.Linear(128, 64)\n",
    "        #self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    #def forward(self, x):\n",
    "        #x = x.view(-1, 28*28)\n",
    "        #x = nn.functional.relu(self.fc1(x))\n",
    "        #x = nn.functional.relu(self.fc2(x))\n",
    "        #x = self.fc3(x)\n",
    "        #return x\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        x = nn.functional.relu(self.fc5(x))\n",
    "        x = nn.functional.log_softmax(self.fc6(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdedb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72b47828",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d10eab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.302\n",
      "[1,   400] loss: 2.297\n",
      "[1,   600] loss: 2.291\n",
      "[1,   800] loss: 2.281\n",
      "Epoch 1/10.. Train loss: 0.334.. Test loss: 2.256.. Test accuracy: 0.194\n",
      "[2,   200] loss: 2.231\n",
      "[2,   400] loss: 2.065\n",
      "[2,   600] loss: 1.591\n",
      "[2,   800] loss: 1.205\n",
      "Epoch 2/10.. Train loss: 0.154.. Test loss: 0.968.. Test accuracy: 0.682\n",
      "[3,   200] loss: 0.845\n",
      "[3,   400] loss: 0.649\n",
      "[3,   600] loss: 0.560\n",
      "[3,   800] loss: 0.482\n",
      "Epoch 3/10.. Train loss: 0.070.. Test loss: 0.433.. Test accuracy: 0.868\n",
      "[4,   200] loss: 0.416\n",
      "[4,   400] loss: 0.383\n",
      "[4,   600] loss: 0.358\n",
      "[4,   800] loss: 0.354\n",
      "Epoch 4/10.. Train loss: 0.050.. Test loss: 0.315.. Test accuracy: 0.906\n",
      "[5,   200] loss: 0.301\n",
      "[5,   400] loss: 0.305\n",
      "[5,   600] loss: 0.276\n",
      "[5,   800] loss: 0.277\n",
      "Epoch 5/10.. Train loss: 0.038.. Test loss: 0.240.. Test accuracy: 0.930\n",
      "[6,   200] loss: 0.248\n",
      "[6,   400] loss: 0.227\n",
      "[6,   600] loss: 0.221\n",
      "[6,   800] loss: 0.212\n",
      "Epoch 6/10.. Train loss: 0.030.. Test loss: 0.197.. Test accuracy: 0.939\n",
      "[7,   200] loss: 0.202\n",
      "[7,   400] loss: 0.181\n",
      "[7,   600] loss: 0.172\n",
      "[7,   800] loss: 0.184\n",
      "Epoch 7/10.. Train loss: 0.025.. Test loss: 0.178.. Test accuracy: 0.945\n",
      "[8,   200] loss: 0.162\n",
      "[8,   400] loss: 0.166\n",
      "[8,   600] loss: 0.147\n",
      "[8,   800] loss: 0.149\n",
      "Epoch 8/10.. Train loss: 0.022.. Test loss: 0.199.. Test accuracy: 0.938\n",
      "[9,   200] loss: 0.132\n",
      "[9,   400] loss: 0.128\n",
      "[9,   600] loss: 0.137\n",
      "[9,   800] loss: 0.131\n",
      "Epoch 9/10.. Train loss: 0.020.. Test loss: 0.151.. Test accuracy: 0.956\n",
      "[10,   200] loss: 0.120\n",
      "[10,   400] loss: 0.115\n",
      "[10,   600] loss: 0.118\n",
      "[10,   800] loss: 0.105\n",
      "Epoch 10/10.. Train loss: 0.018.. Test loss: 0.139.. Test accuracy: 0.956\n",
      "[11,   200] loss: 0.097\n",
      "[11,   400] loss: 0.109\n",
      "[11,   600] loss: 0.108\n",
      "[11,   800] loss: 0.106\n",
      "Epoch 11/10.. Train loss: 0.013.. Test loss: 0.113.. Test accuracy: 0.967\n",
      "[12,   200] loss: 0.089\n",
      "[12,   400] loss: 0.093\n",
      "[12,   600] loss: 0.096\n",
      "[12,   800] loss: 0.085\n",
      "Epoch 12/10.. Train loss: 0.013.. Test loss: 0.107.. Test accuracy: 0.967\n",
      "[13,   200] loss: 0.083\n",
      "[13,   400] loss: 0.083\n",
      "[13,   600] loss: 0.081\n",
      "[13,   800] loss: 0.082\n",
      "Epoch 13/10.. Train loss: 0.011.. Test loss: 0.104.. Test accuracy: 0.969\n",
      "[14,   200] loss: 0.069\n",
      "[14,   400] loss: 0.075\n",
      "[14,   600] loss: 0.075\n",
      "[14,   800] loss: 0.075\n",
      "Epoch 14/10.. Train loss: 0.010.. Test loss: 0.105.. Test accuracy: 0.970\n",
      "[15,   200] loss: 0.060\n",
      "[15,   400] loss: 0.061\n",
      "[15,   600] loss: 0.066\n",
      "[15,   800] loss: 0.070\n",
      "Epoch 15/10.. Train loss: 0.010.. Test loss: 0.093.. Test accuracy: 0.973\n",
      "[16,   200] loss: 0.057\n",
      "[16,   400] loss: 0.062\n",
      "[16,   600] loss: 0.057\n",
      "[16,   800] loss: 0.061\n",
      "Epoch 16/10.. Train loss: 0.008.. Test loss: 0.088.. Test accuracy: 0.974\n",
      "[17,   200] loss: 0.049\n",
      "[17,   400] loss: 0.054\n",
      "[17,   600] loss: 0.051\n",
      "[17,   800] loss: 0.056\n",
      "Epoch 17/10.. Train loss: 0.008.. Test loss: 0.148.. Test accuracy: 0.955\n",
      "[18,   200] loss: 0.048\n",
      "[18,   400] loss: 0.045\n",
      "[18,   600] loss: 0.053\n",
      "[18,   800] loss: 0.045\n",
      "Epoch 18/10.. Train loss: 0.011.. Test loss: 0.099.. Test accuracy: 0.972\n",
      "[19,   200] loss: 0.036\n",
      "[19,   400] loss: 0.048\n",
      "[19,   600] loss: 0.041\n",
      "[19,   800] loss: 0.042\n",
      "Epoch 19/10.. Train loss: 0.007.. Test loss: 0.095.. Test accuracy: 0.973\n",
      "[20,   200] loss: 0.041\n",
      "[20,   400] loss: 0.033\n",
      "[20,   600] loss: 0.035\n",
      "[20,   800] loss: 0.039\n",
      "Epoch 20/10.. Train loss: 0.006.. Test loss: 0.096.. Test accuracy: 0.972\n",
      "[21,   200] loss: 0.031\n",
      "[21,   400] loss: 0.035\n",
      "[21,   600] loss: 0.034\n",
      "[21,   800] loss: 0.036\n",
      "Epoch 21/10.. Train loss: 0.005.. Test loss: 0.084.. Test accuracy: 0.976\n",
      "[22,   200] loss: 0.028\n",
      "[22,   400] loss: 0.030\n",
      "[22,   600] loss: 0.030\n",
      "[22,   800] loss: 0.033\n",
      "Epoch 22/10.. Train loss: 0.005.. Test loss: 0.087.. Test accuracy: 0.976\n",
      "[23,   200] loss: 0.027\n",
      "[23,   400] loss: 0.024\n",
      "[23,   600] loss: 0.029\n",
      "[23,   800] loss: 0.028\n",
      "Epoch 23/10.. Train loss: 0.003.. Test loss: 0.084.. Test accuracy: 0.977\n",
      "[24,   200] loss: 0.021\n",
      "[24,   400] loss: 0.027\n",
      "[24,   600] loss: 0.023\n",
      "[24,   800] loss: 0.024\n",
      "Epoch 24/10.. Train loss: 0.004.. Test loss: 0.084.. Test accuracy: 0.977\n",
      "[25,   200] loss: 0.021\n",
      "[25,   400] loss: 0.025\n",
      "[25,   600] loss: 0.022\n",
      "[25,   800] loss: 0.024\n",
      "Epoch 25/10.. Train loss: 0.004.. Test loss: 0.082.. Test accuracy: 0.977\n",
      "[26,   200] loss: 0.020\n",
      "[26,   400] loss: 0.015\n",
      "[26,   600] loss: 0.015\n",
      "[26,   800] loss: 0.026\n",
      "Epoch 26/10.. Train loss: 0.003.. Test loss: 0.083.. Test accuracy: 0.978\n",
      "[27,   200] loss: 0.015\n",
      "[27,   400] loss: 0.016\n",
      "[27,   600] loss: 0.017\n",
      "[27,   800] loss: 0.020\n",
      "Epoch 27/10.. Train loss: 0.003.. Test loss: 0.159.. Test accuracy: 0.954\n",
      "[28,   200] loss: 0.015\n",
      "[28,   400] loss: 0.016\n",
      "[28,   600] loss: 0.017\n",
      "[28,   800] loss: 0.015\n",
      "Epoch 28/10.. Train loss: 0.003.. Test loss: 0.164.. Test accuracy: 0.954\n",
      "[29,   200] loss: 0.012\n",
      "[29,   400] loss: 0.012\n",
      "[29,   600] loss: 0.013\n",
      "[29,   800] loss: 0.015\n",
      "Epoch 29/10.. Train loss: 0.002.. Test loss: 0.085.. Test accuracy: 0.978\n",
      "[30,   200] loss: 0.008\n",
      "[30,   400] loss: 0.010\n",
      "[30,   600] loss: 0.013\n",
      "[30,   800] loss: 0.016\n",
      "Epoch 30/10.. Train loss: 0.002.. Test loss: 0.087.. Test accuracy: 0.978\n",
      "[31,   200] loss: 0.007\n",
      "[31,   400] loss: 0.009\n",
      "[31,   600] loss: 0.009\n",
      "[31,   800] loss: 0.105\n",
      "Epoch 31/10.. Train loss: 0.007.. Test loss: 0.083.. Test accuracy: 0.976\n",
      "[32,   200] loss: 0.024\n",
      "[32,   400] loss: 0.016\n",
      "[32,   600] loss: 0.015\n",
      "[32,   800] loss: 0.014\n",
      "Epoch 32/10.. Train loss: 0.002.. Test loss: 0.091.. Test accuracy: 0.977\n",
      "[33,   200] loss: 0.009\n",
      "[33,   400] loss: 0.011\n",
      "[33,   600] loss: 0.010\n",
      "[33,   800] loss: 0.012\n",
      "Epoch 33/10.. Train loss: 0.001.. Test loss: 0.082.. Test accuracy: 0.979\n",
      "[34,   200] loss: 0.008\n",
      "[34,   400] loss: 0.010\n",
      "[34,   600] loss: 0.007\n",
      "[34,   800] loss: 0.008\n",
      "Epoch 34/10.. Train loss: 0.001.. Test loss: 0.090.. Test accuracy: 0.979\n",
      "[35,   200] loss: 0.005\n",
      "[35,   400] loss: 0.006\n",
      "[35,   600] loss: 0.009\n",
      "[35,   800] loss: 0.010\n",
      "Epoch 35/10.. Train loss: 0.001.. Test loss: 0.092.. Test accuracy: 0.978\n",
      "[36,   200] loss: 0.005\n",
      "[36,   400] loss: 0.006\n",
      "[36,   600] loss: 0.006\n",
      "[36,   800] loss: 0.005\n",
      "Epoch 36/10.. Train loss: 0.001.. Test loss: 0.091.. Test accuracy: 0.978\n",
      "[37,   200] loss: 0.004\n",
      "[37,   400] loss: 0.006\n",
      "[37,   600] loss: 0.005\n",
      "[37,   800] loss: 0.005\n",
      "Epoch 37/10.. Train loss: 0.001.. Test loss: 0.089.. Test accuracy: 0.978\n",
      "[38,   200] loss: 0.004\n",
      "[38,   400] loss: 0.003\n",
      "[38,   600] loss: 0.003\n",
      "[38,   800] loss: 0.007\n",
      "Epoch 38/10.. Train loss: 0.001.. Test loss: 0.091.. Test accuracy: 0.979\n",
      "[39,   200] loss: 0.003\n",
      "[39,   400] loss: 0.004\n",
      "[39,   600] loss: 0.003\n",
      "[39,   800] loss: 0.004\n",
      "Epoch 39/10.. Train loss: 0.000.. Test loss: 0.098.. Test accuracy: 0.978\n",
      "[40,   200] loss: 0.002\n",
      "[40,   400] loss: 0.001\n",
      "[40,   600] loss: 0.003\n",
      "[40,   800] loss: 0.002\n",
      "Epoch 40/10.. Train loss: 0.000.. Test loss: 0.095.. Test accuracy: 0.978\n",
      "[41,   200] loss: 0.004\n",
      "[41,   400] loss: 0.002\n",
      "[41,   600] loss: 0.002\n",
      "[41,   800] loss: 0.002\n",
      "Epoch 41/10.. Train loss: 0.000.. Test loss: 0.094.. Test accuracy: 0.979\n",
      "[42,   200] loss: 0.001\n",
      "[42,   400] loss: 0.001\n",
      "[42,   600] loss: 0.002\n",
      "[42,   800] loss: 0.001\n",
      "Epoch 42/10.. Train loss: 0.000.. Test loss: 0.098.. Test accuracy: 0.979\n",
      "[43,   200] loss: 0.001\n",
      "[43,   400] loss: 0.001\n",
      "[43,   600] loss: 0.001\n",
      "[43,   800] loss: 0.001\n",
      "Epoch 43/10.. Train loss: 0.000.. Test loss: 0.098.. Test accuracy: 0.979\n",
      "[44,   200] loss: 0.001\n",
      "[44,   400] loss: 0.001\n",
      "[44,   600] loss: 0.001\n",
      "[44,   800] loss: 0.001\n",
      "Epoch 44/10.. Train loss: 0.000.. Test loss: 0.098.. Test accuracy: 0.979\n",
      "[45,   200] loss: 0.001\n",
      "[45,   400] loss: 0.001\n",
      "[45,   600] loss: 0.001\n",
      "[45,   800] loss: 0.001\n",
      "Epoch 45/10.. Train loss: 0.000.. Test loss: 0.100.. Test accuracy: 0.979\n",
      "[46,   200] loss: 0.001\n",
      "[46,   400] loss: 0.001\n",
      "[46,   600] loss: 0.001\n",
      "[46,   800] loss: 0.001\n",
      "Epoch 46/10.. Train loss: 0.000.. Test loss: 0.101.. Test accuracy: 0.980\n",
      "[47,   200] loss: 0.001\n",
      "[47,   400] loss: 0.001\n",
      "[47,   600] loss: 0.001\n",
      "[47,   800] loss: 0.001\n",
      "Epoch 47/10.. Train loss: 0.000.. Test loss: 0.102.. Test accuracy: 0.979\n",
      "[48,   200] loss: 0.001\n",
      "[48,   400] loss: 0.001\n",
      "[48,   600] loss: 0.001\n",
      "[48,   800] loss: 0.001\n",
      "Epoch 48/10.. Train loss: 0.000.. Test loss: 0.104.. Test accuracy: 0.979\n",
      "[49,   200] loss: 0.001\n",
      "[49,   400] loss: 0.001\n",
      "[49,   600] loss: 0.001\n",
      "[49,   800] loss: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/10.. Train loss: 0.000.. Test loss: 0.103.. Test accuracy: 0.979\n",
      "[50,   200] loss: 0.001\n",
      "[50,   400] loss: 0.001\n",
      "[50,   600] loss: 0.001\n",
      "[50,   800] loss: 0.001\n",
      "Epoch 50/10.. Train loss: 0.000.. Test loss: 0.103.. Test accuracy: 0.979\n",
      "[51,   200] loss: 0.001\n",
      "[51,   400] loss: 0.000\n",
      "[51,   600] loss: 0.001\n",
      "[51,   800] loss: 0.001\n",
      "Epoch 51/10.. Train loss: 0.000.. Test loss: 0.103.. Test accuracy: 0.979\n",
      "[52,   200] loss: 0.001\n",
      "[52,   400] loss: 0.001\n",
      "[52,   600] loss: 0.001\n",
      "[52,   800] loss: 0.001\n",
      "Epoch 52/10.. Train loss: 0.000.. Test loss: 0.105.. Test accuracy: 0.978\n",
      "[53,   200] loss: 0.001\n",
      "[53,   400] loss: 0.000\n",
      "[53,   600] loss: 0.001\n",
      "[53,   800] loss: 0.001\n",
      "Epoch 53/10.. Train loss: 0.000.. Test loss: 0.106.. Test accuracy: 0.978\n",
      "[54,   200] loss: 0.000\n",
      "[54,   400] loss: 0.000\n",
      "[54,   600] loss: 0.000\n",
      "[54,   800] loss: 0.001\n",
      "Epoch 54/10.. Train loss: 0.000.. Test loss: 0.108.. Test accuracy: 0.978\n",
      "[55,   200] loss: 0.000\n",
      "[55,   400] loss: 0.000\n",
      "[55,   600] loss: 0.001\n",
      "[55,   800] loss: 0.000\n",
      "Epoch 55/10.. Train loss: 0.000.. Test loss: 0.107.. Test accuracy: 0.978\n",
      "[56,   200] loss: 0.000\n",
      "[56,   400] loss: 0.000\n",
      "[56,   600] loss: 0.000\n",
      "[56,   800] loss: 0.000\n",
      "Epoch 56/10.. Train loss: 0.000.. Test loss: 0.107.. Test accuracy: 0.978\n",
      "[57,   200] loss: 0.000\n",
      "[57,   400] loss: 0.000\n",
      "[57,   600] loss: 0.000\n",
      "[57,   800] loss: 0.000\n",
      "Epoch 57/10.. Train loss: 0.000.. Test loss: 0.108.. Test accuracy: 0.979\n",
      "[58,   200] loss: 0.000\n",
      "[58,   400] loss: 0.000\n",
      "[58,   600] loss: 0.000\n",
      "[58,   800] loss: 0.000\n",
      "Epoch 58/10.. Train loss: 0.000.. Test loss: 0.108.. Test accuracy: 0.978\n",
      "[59,   200] loss: 0.000\n",
      "[59,   400] loss: 0.000\n",
      "[59,   600] loss: 0.000\n",
      "[59,   800] loss: 0.000\n",
      "Epoch 59/10.. Train loss: 0.000.. Test loss: 0.110.. Test accuracy: 0.979\n",
      "[60,   200] loss: 0.000\n",
      "[60,   400] loss: 0.000\n",
      "[60,   600] loss: 0.000\n",
      "[60,   800] loss: 0.000\n",
      "Epoch 60/10.. Train loss: 0.000.. Test loss: 0.109.. Test accuracy: 0.979\n",
      "[61,   200] loss: 0.000\n",
      "[61,   400] loss: 0.000\n",
      "[61,   600] loss: 0.000\n",
      "[61,   800] loss: 0.000\n",
      "Epoch 61/10.. Train loss: 0.000.. Test loss: 0.110.. Test accuracy: 0.978\n",
      "[62,   200] loss: 0.000\n",
      "[62,   400] loss: 0.000\n",
      "[62,   600] loss: 0.000\n",
      "[62,   800] loss: 0.000\n",
      "Epoch 62/10.. Train loss: 0.000.. Test loss: 0.110.. Test accuracy: 0.978\n",
      "[63,   200] loss: 0.000\n",
      "[63,   400] loss: 0.000\n",
      "[63,   600] loss: 0.000\n",
      "[63,   800] loss: 0.000\n",
      "Epoch 63/10.. Train loss: 0.000.. Test loss: 0.111.. Test accuracy: 0.979\n",
      "[64,   200] loss: 0.000\n",
      "[64,   400] loss: 0.000\n",
      "[64,   600] loss: 0.000\n",
      "[64,   800] loss: 0.000\n",
      "Epoch 64/10.. Train loss: 0.000.. Test loss: 0.111.. Test accuracy: 0.979\n",
      "[65,   200] loss: 0.000\n",
      "[65,   400] loss: 0.000\n",
      "[65,   600] loss: 0.000\n",
      "[65,   800] loss: 0.000\n",
      "Epoch 65/10.. Train loss: 0.000.. Test loss: 0.112.. Test accuracy: 0.979\n",
      "[66,   200] loss: 0.000\n",
      "[66,   400] loss: 0.000\n",
      "[66,   600] loss: 0.000\n",
      "[66,   800] loss: 0.000\n",
      "Epoch 66/10.. Train loss: 0.000.. Test loss: 0.113.. Test accuracy: 0.979\n",
      "[67,   200] loss: 0.000\n",
      "[67,   400] loss: 0.000\n",
      "[67,   600] loss: 0.000\n",
      "[67,   800] loss: 0.000\n",
      "Epoch 67/10.. Train loss: 0.000.. Test loss: 0.112.. Test accuracy: 0.979\n",
      "[68,   200] loss: 0.000\n",
      "[68,   400] loss: 0.000\n",
      "[68,   600] loss: 0.000\n",
      "[68,   800] loss: 0.000\n",
      "Epoch 68/10.. Train loss: 0.000.. Test loss: 0.113.. Test accuracy: 0.979\n",
      "[69,   200] loss: 0.000\n",
      "[69,   400] loss: 0.000\n",
      "[69,   600] loss: 0.000\n",
      "[69,   800] loss: 0.000\n",
      "Epoch 69/10.. Train loss: 0.000.. Test loss: 0.112.. Test accuracy: 0.979\n",
      "[70,   200] loss: 0.000\n",
      "[70,   400] loss: 0.000\n",
      "[70,   600] loss: 0.000\n",
      "[70,   800] loss: 0.000\n",
      "Epoch 70/10.. Train loss: 0.000.. Test loss: 0.113.. Test accuracy: 0.979\n",
      "[71,   200] loss: 0.000\n",
      "[71,   400] loss: 0.000\n",
      "[71,   600] loss: 0.000\n",
      "[71,   800] loss: 0.000\n",
      "Epoch 71/10.. Train loss: 0.000.. Test loss: 0.114.. Test accuracy: 0.979\n",
      "[72,   200] loss: 0.000\n",
      "[72,   400] loss: 0.000\n",
      "[72,   600] loss: 0.000\n",
      "[72,   800] loss: 0.000\n",
      "Epoch 72/10.. Train loss: 0.000.. Test loss: 0.114.. Test accuracy: 0.979\n",
      "[73,   200] loss: 0.000\n",
      "[73,   400] loss: 0.000\n",
      "[73,   600] loss: 0.000\n",
      "[73,   800] loss: 0.000\n",
      "Epoch 73/10.. Train loss: 0.000.. Test loss: 0.115.. Test accuracy: 0.979\n",
      "[74,   200] loss: 0.000\n",
      "[74,   400] loss: 0.000\n",
      "[74,   600] loss: 0.000\n",
      "[74,   800] loss: 0.000\n",
      "Epoch 74/10.. Train loss: 0.000.. Test loss: 0.115.. Test accuracy: 0.978\n",
      "[75,   200] loss: 0.000\n",
      "[75,   400] loss: 0.000\n",
      "[75,   600] loss: 0.000\n",
      "[75,   800] loss: 0.000\n",
      "Epoch 75/10.. Train loss: 0.000.. Test loss: 0.115.. Test accuracy: 0.979\n",
      "[76,   200] loss: 0.000\n",
      "[76,   400] loss: 0.000\n",
      "[76,   600] loss: 0.000\n",
      "[76,   800] loss: 0.000\n",
      "Epoch 76/10.. Train loss: 0.000.. Test loss: 0.115.. Test accuracy: 0.979\n",
      "[77,   200] loss: 0.000\n",
      "[77,   400] loss: 0.000\n",
      "[77,   600] loss: 0.000\n",
      "[77,   800] loss: 0.000\n",
      "Epoch 77/10.. Train loss: 0.000.. Test loss: 0.116.. Test accuracy: 0.979\n",
      "[78,   200] loss: 0.000\n",
      "[78,   400] loss: 0.000\n",
      "[78,   600] loss: 0.000\n",
      "[78,   800] loss: 0.000\n",
      "Epoch 78/10.. Train loss: 0.000.. Test loss: 0.116.. Test accuracy: 0.979\n",
      "[79,   200] loss: 0.000\n",
      "[79,   400] loss: 0.000\n",
      "[79,   600] loss: 0.000\n",
      "[79,   800] loss: 0.000\n",
      "Epoch 79/10.. Train loss: 0.000.. Test loss: 0.117.. Test accuracy: 0.979\n",
      "[80,   200] loss: 0.000\n",
      "[80,   400] loss: 0.000\n",
      "[80,   600] loss: 0.000\n",
      "[80,   800] loss: 0.000\n",
      "Epoch 80/10.. Train loss: 0.000.. Test loss: 0.117.. Test accuracy: 0.979\n",
      "[81,   200] loss: 0.000\n",
      "[81,   400] loss: 0.000\n",
      "[81,   600] loss: 0.000\n",
      "[81,   800] loss: 0.000\n",
      "Epoch 81/10.. Train loss: 0.000.. Test loss: 0.117.. Test accuracy: 0.979\n",
      "[82,   200] loss: 0.000\n",
      "[82,   400] loss: 0.000\n",
      "[82,   600] loss: 0.000\n",
      "[82,   800] loss: 0.000\n",
      "Epoch 82/10.. Train loss: 0.000.. Test loss: 0.118.. Test accuracy: 0.979\n",
      "[83,   200] loss: 0.000\n",
      "[83,   400] loss: 0.000\n",
      "[83,   600] loss: 0.000\n",
      "[83,   800] loss: 0.000\n",
      "Epoch 83/10.. Train loss: 0.000.. Test loss: 0.117.. Test accuracy: 0.979\n",
      "[84,   200] loss: 0.000\n",
      "[84,   400] loss: 0.000\n",
      "[84,   600] loss: 0.000\n",
      "[84,   800] loss: 0.000\n",
      "Epoch 84/10.. Train loss: 0.000.. Test loss: 0.118.. Test accuracy: 0.979\n",
      "[85,   200] loss: 0.000\n",
      "[85,   400] loss: 0.000\n",
      "[85,   600] loss: 0.000\n",
      "[85,   800] loss: 0.000\n",
      "Epoch 85/10.. Train loss: 0.000.. Test loss: 0.118.. Test accuracy: 0.979\n",
      "[86,   200] loss: 0.000\n",
      "[86,   400] loss: 0.000\n",
      "[86,   600] loss: 0.000\n",
      "[86,   800] loss: 0.000\n",
      "Epoch 86/10.. Train loss: 0.000.. Test loss: 0.118.. Test accuracy: 0.979\n",
      "[87,   200] loss: 0.000\n",
      "[87,   400] loss: 0.000\n",
      "[87,   600] loss: 0.000\n",
      "[87,   800] loss: 0.000\n",
      "Epoch 87/10.. Train loss: 0.000.. Test loss: 0.118.. Test accuracy: 0.979\n",
      "[88,   200] loss: 0.000\n",
      "[88,   400] loss: 0.000\n",
      "[88,   600] loss: 0.000\n",
      "[88,   800] loss: 0.000\n",
      "Epoch 88/10.. Train loss: 0.000.. Test loss: 0.119.. Test accuracy: 0.979\n",
      "[89,   200] loss: 0.000\n",
      "[89,   400] loss: 0.000\n",
      "[89,   600] loss: 0.000\n",
      "[89,   800] loss: 0.000\n",
      "Epoch 89/10.. Train loss: 0.000.. Test loss: 0.119.. Test accuracy: 0.979\n",
      "[90,   200] loss: 0.000\n",
      "[90,   400] loss: 0.000\n",
      "[90,   600] loss: 0.000\n",
      "[90,   800] loss: 0.000\n",
      "Epoch 90/10.. Train loss: 0.000.. Test loss: 0.120.. Test accuracy: 0.979\n",
      "[91,   200] loss: 0.000\n",
      "[91,   400] loss: 0.000\n",
      "[91,   600] loss: 0.000\n",
      "[91,   800] loss: 0.000\n",
      "Epoch 91/10.. Train loss: 0.000.. Test loss: 0.120.. Test accuracy: 0.978\n",
      "[92,   200] loss: 0.000\n",
      "[92,   400] loss: 0.000\n",
      "[92,   600] loss: 0.000\n",
      "[92,   800] loss: 0.000\n",
      "Epoch 92/10.. Train loss: 0.000.. Test loss: 0.120.. Test accuracy: 0.979\n",
      "[93,   200] loss: 0.000\n",
      "[93,   400] loss: 0.000\n",
      "[93,   600] loss: 0.000\n",
      "[93,   800] loss: 0.000\n",
      "Epoch 93/10.. Train loss: 0.000.. Test loss: 0.120.. Test accuracy: 0.978\n",
      "[94,   200] loss: 0.000\n",
      "[94,   400] loss: 0.000\n",
      "[94,   600] loss: 0.000\n",
      "[94,   800] loss: 0.000\n",
      "Epoch 94/10.. Train loss: 0.000.. Test loss: 0.120.. Test accuracy: 0.979\n",
      "[95,   200] loss: 0.000\n",
      "[95,   400] loss: 0.000\n",
      "[95,   600] loss: 0.000\n",
      "[95,   800] loss: 0.000\n",
      "Epoch 95/10.. Train loss: 0.000.. Test loss: 0.120.. Test accuracy: 0.979\n",
      "[96,   200] loss: 0.000\n",
      "[96,   400] loss: 0.000\n",
      "[96,   600] loss: 0.000\n",
      "[96,   800] loss: 0.000\n",
      "Epoch 96/10.. Train loss: 0.000.. Test loss: 0.121.. Test accuracy: 0.979\n",
      "[97,   200] loss: 0.000\n",
      "[97,   400] loss: 0.000\n",
      "[97,   600] loss: 0.000\n",
      "[97,   800] loss: 0.000\n",
      "Epoch 97/10.. Train loss: 0.000.. Test loss: 0.121.. Test accuracy: 0.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98,   200] loss: 0.000\n",
      "[98,   400] loss: 0.000\n",
      "[98,   600] loss: 0.000\n",
      "[98,   800] loss: 0.000\n",
      "Epoch 98/10.. Train loss: 0.000.. Test loss: 0.121.. Test accuracy: 0.979\n",
      "[99,   200] loss: 0.000\n",
      "[99,   400] loss: 0.000\n",
      "[99,   600] loss: 0.000\n",
      "[99,   800] loss: 0.000\n",
      "Epoch 99/10.. Train loss: 0.000.. Test loss: 0.121.. Test accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "# Обучение нейронной сети\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(1, 100):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    train_losses.append(running_loss / len(trainloader))\n",
    "\n",
    "    # Вычисление потерь на тестовом датасете\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            logps = net(images)\n",
    "            test_loss += criterion(logps, labels)\n",
    "\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "    test_losses.append(test_loss / len(testloader))\n",
    "\n",
    "    print(f\"Epoch {epoch}/{10}.. \"\n",
    "          f\"Train loss: {running_loss/len(trainloader):.3f}.. \"\n",
    "          f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "          f\"Test accuracy: {accuracy/len(testloader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3093cc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Визуализация результатов\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(train_losses, label='Training loss')\n",
    "ax.plot(test_losses, label='Validation loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2036b3",
   "metadata": {},
   "source": [
    "#### Действия, которые могут привести к переобучению:\n",
    "\n",
    "Увеличение количества эпох обучения. Большее количество эпох может привести к тому, что модель будет лучше запоминать обучающие данные и хуже обобщать на новые данные.\n",
    "\n",
    "Увеличение количества параметров модели. Например, можно увеличить количество нейронов в полносвязных слоях или добавить новые слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce00c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
